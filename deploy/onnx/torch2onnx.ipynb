{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNRapWhnoK9D8OBTvj+CQUR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nihalsuri/thermal-anomaly-detection/blob/main/deploy/onnx/torch2onnx.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch to ONNX"
      ],
      "metadata": {
        "id": "Vb7iUBi4SqQg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bdpHcZilN_gT"
      },
      "outputs": [],
      "source": [
        "import torch \n",
        "import torchvision \n",
        "import onnx\n",
        "from PIL import Image\n",
        "from torch.autograd import Variable\n",
        "import numpy as np \n",
        "import timm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device_name = torch.cuda.get_device_name()\n",
        "print(device_name)\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_kj3NteaNFo",
        "outputId": "b3fa1351-07ff-49ff-bcd5-9461cac5810f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA GeForce GTX 1660 Ti with Max-Q Design\n",
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = input('Enter Model name: ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oI-VjWdRafht",
        "outputId": "2b4cbac7-1557-42c3-a1d4-d404c461d39d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter Model name: resnet10t\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = timm.create_model(model_name, pretrained=True, num_classes=3)\n",
        "model = model.cuda() if device else model\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPRSo9ghbnAR",
        "outputId": "03d322db-845d-4780-9235-354e65a6ad8c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Sequential(\n",
              "    (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(24, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  )\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (act1): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "        (1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "        (1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "        (1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
              "  (fc): Linear(in_features=512, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model = model\n",
        "trained_model.load_state_dict(torch.load(\"C:/Users/Nihal/Desktop/resnet10t-timm-2.pt\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yv48ajVOcHHz",
        "outputId": "6e90dc0e-0ae7-4c49-9ffb-9dc42e07116e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_input = Variable(torch.randn(8, 3, 140, 230)).cuda()"
      ],
      "metadata": {
        "id": "0OhCuR7DfaOS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.onnx.export(trained_model, dummy_input, \"C:/Users/Nihal/Desktop/thermal-anomaly-detection/deploy/onnx/resnet10t-1.onnx\")"
      ],
      "metadata": {
        "id": "PkUdJkt-k12C"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Verification"
      ],
      "metadata": {
        "id": "HYhHgqLxSyaG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "onnx_model = onnx.load(\"C:/Users/Nihal/Desktop/thermal-anomaly-detection/deploy/onnx/resnet10t-1.onnx\")\n",
        "onnx.checker.check_model(onnx_model)\n",
        "onnx.helper.printable_graph(onnx_model.graph)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdsQwi6XS3Q2",
        "outputId": "0c68aa6c-d204-4d20-ec8a-a5213971ee76"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'graph torch_jit (\\n  %input.1[FLOAT, 8x3x140x230]\\n) initializers (\\n  %fc.weight[FLOAT, 3x512]\\n  %fc.bias[FLOAT, 3]\\n  %onnx::Conv_138[FLOAT, 24x3x3x3]\\n  %onnx::Conv_139[FLOAT, 24]\\n  %onnx::Conv_141[FLOAT, 32x24x3x3]\\n  %onnx::Conv_142[FLOAT, 32]\\n  %onnx::Conv_144[FLOAT, 64x32x3x3]\\n  %onnx::Conv_145[FLOAT, 64]\\n  %onnx::Conv_147[FLOAT, 64x64x3x3]\\n  %onnx::Conv_148[FLOAT, 64]\\n  %onnx::Conv_150[FLOAT, 64x64x3x3]\\n  %onnx::Conv_151[FLOAT, 64]\\n  %onnx::Conv_153[FLOAT, 128x64x3x3]\\n  %onnx::Conv_154[FLOAT, 128]\\n  %onnx::Conv_156[FLOAT, 128x128x3x3]\\n  %onnx::Conv_157[FLOAT, 128]\\n  %onnx::Conv_159[FLOAT, 128x64x1x1]\\n  %onnx::Conv_160[FLOAT, 128]\\n  %onnx::Conv_162[FLOAT, 256x128x3x3]\\n  %onnx::Conv_163[FLOAT, 256]\\n  %onnx::Conv_165[FLOAT, 256x256x3x3]\\n  %onnx::Conv_166[FLOAT, 256]\\n  %onnx::Conv_168[FLOAT, 256x128x1x1]\\n  %onnx::Conv_169[FLOAT, 256]\\n  %onnx::Conv_171[FLOAT, 512x256x3x3]\\n  %onnx::Conv_172[FLOAT, 512]\\n  %onnx::Conv_174[FLOAT, 512x512x3x3]\\n  %onnx::Conv_175[FLOAT, 512]\\n  %onnx::Conv_177[FLOAT, 512x256x1x1]\\n  %onnx::Conv_178[FLOAT, 512]\\n) {\\n  %/conv1/conv1.0/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%input.1, %onnx::Conv_138, %onnx::Conv_139)\\n  %/conv1/conv1.2/Relu_output_0 = Relu(%/conv1/conv1.0/Conv_output_0)\\n  %/conv1/conv1.3/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/conv1/conv1.2/Relu_output_0, %onnx::Conv_141, %onnx::Conv_142)\\n  %/conv1/conv1.5/Relu_output_0 = Relu(%/conv1/conv1.3/Conv_output_0)\\n  %/conv1/conv1.6/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/conv1/conv1.5/Relu_output_0, %onnx::Conv_144, %onnx::Conv_145)\\n  %/act1/Relu_output_0 = Relu(%/conv1/conv1.6/Conv_output_0)\\n  %/maxpool/MaxPool_output_0 = MaxPool[ceil_mode = 0, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%/act1/Relu_output_0)\\n  %/layer1/layer1.0/conv1/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/maxpool/MaxPool_output_0, %onnx::Conv_147, %onnx::Conv_148)\\n  %/layer1/layer1.0/act1/Relu_output_0 = Relu(%/layer1/layer1.0/conv1/Conv_output_0)\\n  %/layer1/layer1.0/conv2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/layer1/layer1.0/act1/Relu_output_0, %onnx::Conv_150, %onnx::Conv_151)\\n  %/layer1/layer1.0/Add_output_0 = Add(%/layer1/layer1.0/conv2/Conv_output_0, %/maxpool/MaxPool_output_0)\\n  %/layer1/layer1.0/act2/Relu_output_0 = Relu(%/layer1/layer1.0/Add_output_0)\\n  %/layer2/layer2.0/conv1/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%/layer1/layer1.0/act2/Relu_output_0, %onnx::Conv_153, %onnx::Conv_154)\\n  %/layer2/layer2.0/act1/Relu_output_0 = Relu(%/layer2/layer2.0/conv1/Conv_output_0)\\n  %/layer2/layer2.0/conv2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/layer2/layer2.0/act1/Relu_output_0, %onnx::Conv_156, %onnx::Conv_157)\\n  %/layer2/layer2.0/downsample/downsample.0/AveragePool_output_0 = AveragePool[ceil_mode = 1, kernel_shape = [2, 2], pads = [0, 0, 0, 0], strides = [2, 2]](%/layer1/layer1.0/act2/Relu_output_0)\\n  %/layer2/layer2.0/downsample/downsample.1/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/layer2/layer2.0/downsample/downsample.0/AveragePool_output_0, %onnx::Conv_159, %onnx::Conv_160)\\n  %/layer2/layer2.0/Add_output_0 = Add(%/layer2/layer2.0/conv2/Conv_output_0, %/layer2/layer2.0/downsample/downsample.1/Conv_output_0)\\n  %/layer2/layer2.0/act2/Relu_output_0 = Relu(%/layer2/layer2.0/Add_output_0)\\n  %/layer3/layer3.0/conv1/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%/layer2/layer2.0/act2/Relu_output_0, %onnx::Conv_162, %onnx::Conv_163)\\n  %/layer3/layer3.0/act1/Relu_output_0 = Relu(%/layer3/layer3.0/conv1/Conv_output_0)\\n  %/layer3/layer3.0/conv2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/layer3/layer3.0/act1/Relu_output_0, %onnx::Conv_165, %onnx::Conv_166)\\n  %/layer3/layer3.0/downsample/downsample.0/AveragePool_output_0 = AveragePool[ceil_mode = 1, kernel_shape = [2, 2], pads = [0, 0, 0, 0], strides = [2, 2]](%/layer2/layer2.0/act2/Relu_output_0)\\n  %/layer3/layer3.0/downsample/downsample.1/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/layer3/layer3.0/downsample/downsample.0/AveragePool_output_0, %onnx::Conv_168, %onnx::Conv_169)\\n  %/layer3/layer3.0/Add_output_0 = Add(%/layer3/layer3.0/conv2/Conv_output_0, %/layer3/layer3.0/downsample/downsample.1/Conv_output_0)\\n  %/layer3/layer3.0/act2/Relu_output_0 = Relu(%/layer3/layer3.0/Add_output_0)\\n  %/layer4/layer4.0/conv1/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%/layer3/layer3.0/act2/Relu_output_0, %onnx::Conv_171, %onnx::Conv_172)\\n  %/layer4/layer4.0/act1/Relu_output_0 = Relu(%/layer4/layer4.0/conv1/Conv_output_0)\\n  %/layer4/layer4.0/conv2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/layer4/layer4.0/act1/Relu_output_0, %onnx::Conv_174, %onnx::Conv_175)\\n  %/layer4/layer4.0/downsample/downsample.0/AveragePool_output_0 = AveragePool[ceil_mode = 1, kernel_shape = [2, 2], pads = [0, 0, 0, 0], strides = [2, 2]](%/layer3/layer3.0/act2/Relu_output_0)\\n  %/layer4/layer4.0/downsample/downsample.1/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%/layer4/layer4.0/downsample/downsample.0/AveragePool_output_0, %onnx::Conv_177, %onnx::Conv_178)\\n  %/layer4/layer4.0/Add_output_0 = Add(%/layer4/layer4.0/conv2/Conv_output_0, %/layer4/layer4.0/downsample/downsample.1/Conv_output_0)\\n  %/layer4/layer4.0/act2/Relu_output_0 = Relu(%/layer4/layer4.0/Add_output_0)\\n  %/global_pool/pool/GlobalAveragePool_output_0 = GlobalAveragePool(%/layer4/layer4.0/act2/Relu_output_0)\\n  %/global_pool/flatten/Flatten_output_0 = Flatten[axis = 1](%/global_pool/pool/GlobalAveragePool_output_0)\\n  %136 = Gemm[alpha = 1, beta = 1, transB = 1](%/global_pool/flatten/Flatten_output_0, %fc.weight, %fc.bias)\\n  return %136\\n}'"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ]
}